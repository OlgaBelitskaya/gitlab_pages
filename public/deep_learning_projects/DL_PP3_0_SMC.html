<!DOCTYPE HTML>
<html>
  <head>
    <meta charset='utf-8'>
    <meta name='viewport' content='width=device-width'>
    <title>üèô DL PP3_0 SMC</title>
    <script src='https://sagecell.sagemath.org/static/embedded_sagecell.js'></script>
    <script>$(function(){
      sagecell.makeSagecell(
        {inputLocation:'div.linked',linked:true,evalButtonText:'run linked cells'});});
    </script>
  </head>
  <style>
    @import 'https://fonts.googleapis.com/css?family=Akronim|Lobster';
    h1,h2,th {color:#348ABD; font-family:Akronim; font-size:120%; text-shadow:4px 4px 4px #aaa;}
    p,a {color:slategray; font-family:Lobster; font-size:120%; text-shadow:4px 4px 4px #aaa;}
    .sagecell .CodeMirror-scroll {min-height:3em; max-height:70em;}
    body {margin:5px 5px 5px 15px;}
  </style>
  <body>
    <h1>üìë &nbsp; Deep Learning. Practice Project 3_0: Product & Brand Recognition</h1>
<a href='https://olgabelitskaya.gitlab.io/index.html'>&#x1F300; &nbsp; Homepage &nbsp; &nbsp;</a>
<a href='https://olgabelitskaya.gitlab.io/deep_learning_projects/index.html'>&#x1F300; &nbsp; Project List &nbsp; &nbsp;</a>
<a href='https://olgabelitskaya.github.io/README.html'>&#x1F300; &nbsp; GitHub Pages &nbsp; &nbsp;</a>
<a href='https://olgabelitskaya.gitlab.io/deep_learning_projects/DL_PP2_0_SMC.html'>
&#x1F300; &nbsp; Previous &nbsp; &nbsp;</a>
<a href='https://olgabelitskaya.gitlab.io/deep_learning_projects/DL_PP4_0_SMC.html'>
&#x1F300; &nbsp; Next &nbsp; &nbsp;</a>
<a href='https://www.instagram.com/olga.belitskaya/'>&#x1F300; &nbsp; Instagram Posts &nbsp; &nbsp;</a>
<a href='https://www.pinterest.ru/olga_belitskaya/code-style/'>&#x1F300; &nbsp; Pinterest Posts</a><br/>
For this project, I have made the database of photos sorted by products and brands.<br/>
The dataset consists of 2184 color images (150x150x3) with 7 brands and 10 products.<br/>
Original photo files are in the .png format and the labels are integers and string values.<br/>
<div class='linked'><script type='text/x-sage'>
import urllib,os; import urllib,os; from IPython.display import HTML
fp='https://olgabelitskaya.github.io/images/'
lf=['0_0_026.jpeg','1_3_003.jpeg','2_2_039.jpeg',
    '3_5_012.jpeg','4_1_019.jpeg','5_9_005.jpeg','6_8_004.jpeg']
for f in lf:
    input_file=urllib.request.urlopen(fp+f)
    output_file=open(f,'wb')
    output_file.write(input_file.read())
    output_file.close(); input_file.close()
fp='https://sagecell.sagemath.org/kernel/'+os.getcwd()[14:]+'/files/'
HTML("""<style>
@import 'https://fonts.googleapis.com/css?family=Akronim|Monsieur La Doulaise';
.sagecell_input {text-shadow:4px 4px 4px #aaa;}
.table1 {width:60%; background-color:silver; color:#ff355f; border:double slategray;}
td,th {border:double slategray; content-align:middle; text-align:center;}
.img1 {width:70px; height:70px; vertical-align:middle;}
.text1rg {display:inline-block; font-size:200%; line-height:1.1;
          padding:10px; font-family:Monsieur La Doulaise,sans-serif;
          background:radial-gradient(
              circle farthest-corner at center center,
              orange,magenta,cyan) no-repeat;
          -webkit-background-clip:text;
          -webkit-text-fill-color:transparent;}
</style><table class='table1'>
<tr style='font-family:Akronim; font-size:120%;'>
<th>Brand</th><th>Image</th></tr>
<tr><td><text class='text1rg'>Christian Louboutin</text></td><td>
<img class='img1' src="""+fp+lf[0]+""" alt='brand0'></td></tr>
<tr><td><text class='text1rg'>Chanel</text></td><td>
<img class='img1' src="""+fp+lf[1]+""" alt='brand1'></td></tr>
<tr><td><text class='text1rg'>Dolce & Gabbana</text></td><td>
<img class='img1'src="""+fp+lf[2]+""" alt='brand2'></td></tr>
<tr><td><text class='text1rg'>Gucci</text></td><td>
<img class='img1' src="""+fp+lf[3]+""" alt='brand3'></td></tr>
<tr><td><text class='text1rg'>Christian Dior</text></td><td>
<img class='img1' src="""+fp+lf[4]+""" alt='brand4'></td></tr>
<tr><td><text class='text1rg'>Versace</text></td><td>
<img class='img1' src="""+fp+lf[5]+""" alt='brand5'></td></tr>
<tr><td><text class='text1rg'>Yves Saint Laurent</text></td><td>
<img class='img1' src="""+fp+lf[6]+""" alt='brand6'></td></tr>
</table>""")
</script></div><br/>
    <h2>‚úíÔ∏è&nbsp;Step 0. Importing Libraries and Defining Helpful Functions</h2>      
<div class='linked'><script type='text/x-sage'>
import warnings; warnings.filterwarnings('ignore')
import tensorflow as tf,numpy as np,pandas as pd
import seaborn as sn,pylab as pl,h5py,urllib
import tensorflow.keras.callbacks as tkc,\
tensorflow.keras.layers as tkl
np.set_printoptions(precision=6)
pl.style.use('seaborn-whitegrid')
model_weights='/tmp/checkpoint'
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
def h5file2data(h5file,cmap,img_size,resize=True):
    with h5py.File(h5file,'r') as f:
        keys=list(f.keys())
        pretty_print('file keys: '+', '.join(keys))
        images=np.array(f[keys[int(0)]])
        labels=np.array(f[keys[int(1)]])
        names=[[el.decode('utf-8') for el in f[keys[i]]]
               for i in range(int(2),len(keys))]
        f.close()
    N=images.shape[int(0)]; n=int(.1*N)
    if resize:
        images=tf.image.resize(images,[img_size,img_size]).numpy()
    shuffle_ids=np.arange(N)
    np.random.RandomState(12).shuffle(shuffle_ids)
    images=images[shuffle_ids]
    labels=np.array([labels[i][shuffle_ids] 
                     for i in range(labels.shape[int(0)])])
    x_test,x_valid,x_train=images[:n],images[n:2*n],images[2*n:]
    y_test,y_valid,y_train=labels[:,:n],labels[:,n:2*n],labels[:,2*n:]
    pretty_print('data outputs: ')
    df=pd.DataFrame([[x_train.shape,x_valid.shape,x_test.shape],
                     [x_train.dtype,x_valid.dtype,x_test.dtype],
                     [y_train.shape,y_valid.shape,y_test.shape],
                     [y_train.dtype,y_valid.dtype,y_test.dtype]],
                    columns=['train','valid','test'],
                    index=['image shape','image type',
                           'label shape','label type'])
    display(df)
    pretty_print('distribution of labels: ')
    idx=['labels %d'%(i+int(1)) for i in range(labels.shape[int(0)])]
    df=pd.DataFrame(labels,index=idx).T
    for i in range(labels.shape[int(0)]):
        df['name %d'%(i+int(1))]=[names[i][l] for l in labels[i]]
    fig=pl.figure(figsize=(9,6))    
    for i in range(labels.shape[int(0)]):
        ax=fig.add_subplot(labels.shape[int(0)],int(1),i+int(1))
        sn.countplot(x='name %s'%(i+1),data=df,palette=cmap,alpha=.5,ax=ax)
    pl.tight_layout(); pl.show()       
    return [names,x_train,x_valid,x_test,y_train,y_valid,y_test]
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
def display_images(images,labels,names,n):
    fig=pl.figure(figsize=(9,n/2))
    randch=np.random.choice(images.shape[0],size=n,replace=False)
    for i,idx in enumerate(randch):
        ax=fig.add_subplot(int(n//5)+1,5,i+1,xticks=[],yticks=[])
        ax.imshow(images[idx],cmap='Greys')
        label=[labels[:,idx]]
        name=[names[i][labels[i][idx]] for i in range(labels.shape[0])]
        ti='{} \n {}'.format(str(label),str(name))
        ax.set_title(ti,fontsize=8)
    pl.tight_layout(); pl.show()
def keras_history_plot(fit_history,fig_size,color):
    keys=list(fit_history.history.keys())
    list_history=[fit_history.history[keys[i]] for i in range(len(keys))]
    dfkeys=pd.DataFrame(list_history).T
    dfkeys.columns=keys
    fig=pl.figure(figsize=(fig_size,fig_size/1.5))
    ax1=fig.add_subplot(2,1,1)
    dfkeys.iloc[:,[int(0),int(2)]].plot(
        ax=ax1,color=['slategray',color],grid=True)
    ax2=fig.add_subplot(2,1,2)
    dfkeys.iloc[:,[int(1),int(3)]].plot(
        ax=ax2,color=['slategray',color],grid=True)
    pl.tight_layout(); pl.show()
</script></div><br/>
    <h2>‚úíÔ∏è&nbsp;Step 1. Loading and Preprocessing the Data</h2>       
<div class='linked'><script type='text/x-sage'>
path='https://raw.githubusercontent.com/OlgaBelitskaya/data_kitchen/main/'
zf='Styles150.h5'; input_file=urllib.request.urlopen(path+zf)
output_file=open(zf,'wb'); output_file.write(input_file.read())
output_file.close(); input_file.close()
img_size=int(48)
[names,x_train,x_valid,x_test,y_train,y_valid,y_test]=\
h5file2data(zf,'Pastel1',img_size)
os.remove(zf)
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
gx_train=np.dot(x_train[...,:3],[.299,.587,.114])
gx_valid=np.dot(x_valid[...,:3],[.299,.587,.114])
gx_test=np.dot(x_test[...,:3],[.299,.587,.114])
display_images(x_train,y_train,names,5)
display_images(gx_test,y_test,names,5)
gx_train=gx_train.reshape(-int(1),img_size,img_size,int(1))
gx_valid=gx_valid.reshape(-int(1),img_size,img_size,int(1))
gx_test=gx_test.reshape(-int(1),img_size,img_size,int(1))
</script></div><br/>
<p>Unfortunately, we can train with guarantee only one neural network at ones.</p>
<p>Please restart the page and load the data again for training each of them.</p>
      <h2>‚úíÔ∏è&nbsp;Step 2. One-Label Classification Models</h2>
<div class='linked'><script type='text/x-sage'>
# Color Images / Brands
def model():
    model=tf.keras.Sequential()
    model.add(tkl.Conv2D(
        int(16),(int(3),int(3)),padding='same', 
        input_shape=x_train.shape[int(1):]))
    model.add(tkl.LeakyReLU(alpha=.02))    
    model.add(tkl.MaxPooling2D(pool_size=(int(2),int(2))))
    model.add(tkl.Dropout(.2))
    model.add(tkl.Conv2D(int(48),(int(3),int(3))))
    model.add(tkl.LeakyReLU(alpha=.02))
    model.add(tkl.MaxPooling2D(pool_size=(int(2),int(2))))
    model.add(tkl.Dropout(.2))   
    model.add(tkl.GlobalMaxPooling2D())     
    model.add(tkl.Dense(int(128)))
    model.add(tkl.LeakyReLU(alpha=.02))
    model.add(tkl.Dropout(.5))    
    model.add(tkl.Dense(int(7)))
    model.add(tkl.Activation('softmax'))   
    model.compile(loss='sparse_categorical_crossentropy', 
                  optimizer='nadam',metrics=['accuracy'])   
    return model
model=model(); model.summary()
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
checkpointer=tkc.ModelCheckpoint(
    filepath=model_weights,verbose=int(0),save_weights_only=True,
    monitor='val_accuracy',mode='max',save_best_only=True)
lr_reduction=tkc.ReduceLROnPlateau(
    monitor='val_loss',patience=int(5),verbose=int(0),factor=.8)
history=model.fit(
    x_train,y_train[int(0),:],epochs=int(10),batch_size=int(16),
    verbose=int(2),validation_data=(x_valid,y_valid[int(0),:]),
    callbacks=[checkpointer,lr_reduction])
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
keras_history_plot(history,9,'#348ABD')
model.load_weights(model_weights)
pretty_print(model.evaluate(x_test,y_test[int(0),:],verbose=int(0)))
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
# Color Images / Products
def model():
    model=tf.keras.Sequential()
    model.add(tkl.Conv2D(
        int(16),(int(3),int(3)),padding='same', 
        input_shape=x_train.shape[int(1):]))
    model.add(tkl.LeakyReLU(alpha=.02))
    model.add(tkl.MaxPooling2D(pool_size=(int(2),int(2))))
    model.add(tkl.Dropout(.2))
    model.add(tkl.Conv2D(int(48),(int(3),int(3))))
    model.add(tkl.LeakyReLU(alpha=.02))
    model.add(tkl.MaxPooling2D(pool_size=(int(2),int(2))))
    model.add(tkl.Dropout(.2))
    model.add(tkl.GlobalMaxPooling2D())
    model.add(tkl.Dense(int(128)))
    model.add(tkl.LeakyReLU(alpha=.02))
    model.add(tkl.Dropout(.5))
    model.add(tkl.Dense(int(10)))
    model.add(tkl.Activation('softmax'))
    model.compile(loss='sparse_categorical_crossentropy',
                  optimizer='nadam',metrics=['accuracy'])   
    return model
model=model()
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
checkpointer=tkc.ModelCheckpoint(
    filepath=model_weights,verbose=int(0),save_weights_only=True,
    monitor='val_accuracy',mode='max',save_best_only=True)
lr_reduction=tkc.ReduceLROnPlateau(
    monitor='val_loss',patience=int(5),verbose=int(0),factor=.8)
history=model.fit(
    x_train,y_train[int(1),:],epochs=int(10),batch_size=int(16),
    verbose=int(2),validation_data=(x_valid,y_valid[int(1),:]),
    callbacks=[checkpointer,lr_reduction])
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
keras_history_plot(history,9,'#348ABD')
model.load_weights(model_weights)
pretty_print(model.evaluate(x_test,y_test[int(1),:],verbose=int(0)))
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
# Grayscaled Images / Brands 
def gray_model():
    model=tf.keras.Sequential()   
    model.add(tkl.Conv2D(
        int(16),(int(3),int(3)),padding='same', 
        input_shape=gx_train.shape[int(1):]))
    model.add(tkl.LeakyReLU(alpha=.02))    
    model.add(tkl.MaxPooling2D(pool_size=(int(2),int(2))))
    model.add(tkl.Dropout(.2))
    model.add(tkl.Conv2D(int(48),(int(3),int(3))))
    model.add(tkl.LeakyReLU(alpha=.02))   
    model.add(tkl.MaxPooling2D(pool_size=(int(2),int(2))))
    model.add(tkl.Dropout(.2))  
    model.add(tkl.GlobalMaxPooling2D())    
    model.add(tkl.Dense(int(128)))
    model.add(tkl.LeakyReLU(alpha=.02))
    model.add(tkl.Dropout(.2))     
    model.add(tkl.Dense(int(32)))
    model.add(tkl.LeakyReLU(alpha=.02))
    model.add(tkl.Dropout(.2))    
    model.add(tkl.Dense(int(7)))
    model.add(tkl.Activation('softmax'))   
    model.compile(loss='sparse_categorical_crossentropy',
                  optimizer='rmsprop',metrics=['accuracy'])
    return model
gray_model=gray_model()
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
checkpointer=tkc.ModelCheckpoint(
    filepath=model_weights,verbose=int(0),save_weights_only=True,
    monitor='val_accuracy',mode='max',save_best_only=True)
lr_reduction=tkc.ReduceLROnPlateau(
    monitor='val_loss',patience=int(5),verbose=int(0),factor=.8)
history=gray_model.fit(
    gx_train,y_train[int(0),:],epochs=int(10),batch_size=int(16),
    verbose=int(2),validation_data=(gx_valid,y_valid[int(0),:]),
    callbacks=[checkpointer,lr_reduction])
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
keras_history_plot(history,9,'#348ABD')
gray_model.load_weights(model_weights)
pretty_print(gray_model.evaluate(gx_test,y_test[int(0),:],verbose=int(0)))
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
# Grayscaled Images / Products
def gray_model():
    model=tf.keras.Sequential()   
    model.add(tkl.Conv2D(
        int(16),(int(3),int(3)),padding='same', 
        input_shape=gx_train.shape[int(1):]))
    model.add(tkl.LeakyReLU(alpha=.02)) 
    model.add(tkl.MaxPooling2D(pool_size=(int(2),int(2))))
    model.add(tkl.Dropout(.2))
    model.add(tkl.Conv2D(int(48),(int(3),int(3))))
    model.add(tkl.LeakyReLU(alpha=.02))    
    model.add(tkl.MaxPooling2D(pool_size=(int(2),int(2))))
    model.add(tkl.Dropout(.2))  
    model.add(tkl.GlobalMaxPooling2D())    
    model.add(tkl.Dense(int(128)))
    model.add(tkl.LeakyReLU(alpha=.02))
    model.add(tkl.Dropout(.2))    
    model.add(tkl.Dense(int(32)))
    model.add(tkl.LeakyReLU(alpha=.02))
    model.add(tkl.Dropout(.2))    
    model.add(tkl.Dense(int(10)))
    model.add(tkl.Activation('softmax'))    
    model.compile(loss='sparse_categorical_crossentropy',
                  optimizer='rmsprop',metrics=['accuracy'])
    return model
gray_model=gray_model()
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
checkpointer=tkc.ModelCheckpoint(
    filepath=model_weights,verbose=int(0),save_weights_only=True,
    monitor='val_accuracy',mode='max',save_best_only=True)
lr_reduction=tkc.ReduceLROnPlateau(
    monitor='val_loss',patience=int(5),verbose=int(0),factor=.8)
history=gray_model.fit(
    gx_train,y_train[int(1),:],epochs=int(10),batch_size=int(16),
    verbose=int(2),validation_data=(gx_valid,y_valid[int(1),:]),
    callbacks=[checkpointer,lr_reduction])
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
keras_history_plot(history,9,'#348ABD')
gray_model.load_weights(model_weights)
pretty_print(gray_model.evaluate(gx_test,y_test[int(1),:],verbose=int(0)))
</script></div><br/>
    <h2>‚úíÔ∏è&nbsp;Step 3. Multi-Label Classification Models</h2>
<div class='linked'><script type='text/x-sage'>
# Color Images
def mmodel():    
    model_input=tkl.Input(shape=(img_size,img_size,int(3)))
    x=tkl.BatchNormalization()(model_input)
    x=tkl.Conv2D(int(16),(int(3),int(3)),padding='same')(model_input)
    x=tkl.LeakyReLU(alpha=.02)(x)
    x=tkl.MaxPooling2D(pool_size=(int(2),int(2)))(x)    
    x=tkl.Dropout(.2)(x)   
    x=tkl.Conv2D(int(48),(int(3),int(3)),padding='same')(x)       
    x=tkl.MaxPooling2D(pool_size=(int(2),int(2)))(x)    
    x=tkl.Dropout(.2)(x)              
    x=tkl.GlobalMaxPooling2D()(x)   
    x=tkl.Dense(int(128))(x)
    x=tkl.LeakyReLU(alpha=.02)(x)    
    x=tkl.Dropout(.5)(x)    
    y1=tkl.Dense(int(7),activation='softmax')(x)
    y2=tkl.Dense(int(10),activation='softmax')(x)   
    model=tf.keras.Model(inputs=model_input,outputs=[y1,y2])    
    model.compile(loss='sparse_categorical_crossentropy',
                  optimizer='nadam',metrics=['accuracy'])
    return model
mmodel=mmodel()
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
checkpointer=tkc.ModelCheckpoint(
    filepath=model_weights,verbose=int(0),save_weights_only=True,
    monitor='val_loss',mode='min',save_best_only=True)
lr_reduction=tkc.ReduceLROnPlateau(
    monitor='val_loss',patience=int(5),verbose=int(2),factor=.8)
history=mmodel.fit(
    x_train,[y_train[int(0),:],y_train[int(1),:]],
    epochs=int(10),batch_size=int(16),verbose=int(2),
    validation_data=(x_valid,[y_valid[int(0),:],y_valid[int(1),:]]),
    callbacks=[checkpointer,lr_reduction])
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
mmodel.load_weights(model_weights)
scores=mmodel.evaluate(
    x_test,[y_test[int(0),:],y_test[int(1),:]],verbose=int(0))
print('Scores: \n',(scores))
print('The Brand Label. Accuracy: %.2f%%'%(scores[int(3)]*int(100)))
print('The Product Label. Accuracy: %.2f%%'%(scores[int(4)]*int(100)))
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
# Grayscaled Images
def gray_mmodel():    
    model_input=tf.keras.Input(shape=(img_size,img_size,int(1)))
    x=tkl.BatchNormalization()(model_input)
    x=tkl.Conv2D(int(16),(int(3),int(3)),padding='same')(model_input)
    x=tkl.LeakyReLU(alpha=.02)(x)
    x=tkl.MaxPooling2D(pool_size=(int(2),int(2)))(x)    
    x=tkl.Dropout(.2)(x)    
    x=tkl.Conv2D(int(48),(int(3),int(3)),padding='same')(x)
    x=tkl.LeakyReLU(alpha=.02)(x)       
    x=tkl.MaxPooling2D(pool_size=(int(2),int(2)))(x)    
    x=tkl.Dropout(.2)(x)             
    x=tkl.GlobalMaxPooling2D()(x)    
    x=tkl.Dense(int(128))(x)
    x=tkl.LeakyReLU(alpha=.02)(x)   
    x=tkl.Dropout(.2)(x)   
    x=tkl.Dense(int(32))(x)
    x=tkl.LeakyReLU(alpha=.02)(x)    
    x=tkl.Dropout(.2)(x)    
    y1=tkl.Dense(int(7),activation='softmax')(x)
    y2=tkl.Dense(int(10),activation='softmax')(x)       
    model=tf.keras.Model(inputs=model_input,outputs=[y1,y2])
    model.compile(loss='sparse_categorical_crossentropy',
                  optimizer='rmsprop',metrics=['accuracy'])   
    return model
gray_mmodel=gray_mmodel()
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
checkpointer=tkc.ModelCheckpoint(
    filepath=model_weights,verbose=int(0),save_weights_only=True,
    monitor='val_loss',mode='min',save_best_only=True)
lr_reduction=tkc.ReduceLROnPlateau(
    monitor='val_loss',patience=int(5),verbose=int(2),factor=.8)
history=gray_mmodel.fit(
    gx_train,[y_train[int(0),:],y_train[int(1),:]],
    epochs=int(10),batch_size=int(16),verbose=int(2),
    validation_data=(gx_valid,[y_valid[int(0),:],y_valid[int(1),:]]),
    callbacks=[checkpointer,lr_reduction])
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
gray_mmodel.load_weights(model_weights)
scores=gray_mmodel.evaluate(
    gx_test,[y_test[int(0),:],y_test[int(1),:]],verbose=int(0))
print('Scores: \n',(scores))
print('The Brand Label. Accuracy: %.2f%%'%(scores[int(3)]*int(100)))
print('The Product Label. Accuracy: %.2f%%'%(scores[int(4)]*int(100)))
</script></div><br/>
  </body>
</html> 
