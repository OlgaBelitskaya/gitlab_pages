<!DOCTYPE HTML>
<html>
  <head>
    <meta charset='utf-8'>
    <meta name='viewport' content='width=device-width'>
    <title>üèô DL PP2_2 SMC</title>
    <script src='https://sagecell.sagemath.org/static/embedded_sagecell.js'></script>
    <script>$(function(){
      sagecell.makeSagecell(
        {inputLocation:'div.linked',linked:true,evalButtonText:'run linked cells'});});
    </script>
  </head>
  <style>
    @import 'https://fonts.googleapis.com/css?family=Akronim|Lobster';
    h1,h2,th {color:#348ABD; font-family:Akronim; font-size:120%; text-shadow:4px 4px 4px #aaa;}
    p,a {color:slategray; font-family:Lobster; font-size:120%; text-shadow:4px 4px 4px #aaa;}
    .sagecell .CodeMirror-scroll {min-height:3em; max-height:70em;}
    body {margin:5px 5px 5px 15px;}
  </style>  
  <body>
    <h1>üìë &nbsp; Deep Learning. Practice Project 2_2: Image Generation</h1>
<a href='https://olgabelitskaya.gitlab.io/index.html'>&#x1F300; &nbsp; Homepage &nbsp; &nbsp;</a>
<a href='https://olgabelitskaya.gitlab.io/deep_learning_projects/index.html'>
&#x1F300; &nbsp; Project List &nbsp; &nbsp;</a>
<a href='https://olgabelitskaya.github.io/README.html'>&#x1F300; &nbsp; GitHub Pages &nbsp; &nbsp;</a>
<a href='https://olgabelitskaya.gitlab.io/deep_learning_projects/DL_PP1_0_SMC.html'>
&#x1F300; &nbsp; Previous &nbsp; &nbsp;</a>
<a href='https://olgabelitskaya.gitlab.io/deep_learning_projects/DL_PP2_0_SMC.html'>
&#x1F300; &nbsp; Main &nbsp; &nbsp;</a>
<a href='https://olgabelitskaya.gitlab.io/deep_learning_projects/DL_PP3_0_SMC.html'>
&#x1F300; &nbsp; Next &nbsp; &nbsp;</a>
<a href='https://www.instagram.com/olga.belitskaya/'>&#x1F300; &nbsp; Instagram Posts &nbsp; &nbsp;</a>
<a href='https://www.pinterest.ru/olga_belitskaya/code-style/'>&#x1F300; &nbsp; Pinterest Posts</a><br/>
For this project, I have created the dataset of color images (32x32x3) with 33 handwritten Russian letters.<br/>
There are four types of letter backgrounds here. <br/>
They are labeled in this dataset as well.<br/>
    <h2>‚úíÔ∏è&nbsp;Step 0. Importing Libraries and Defining Helpful Functions</h2>      
<div class='linked'><script type='text/x-sage'>
import warnings; warnings.filterwarnings('ignore')
import h5py,urllib,tensorflow as tf
import pandas as pd,numpy as np,pylab as pl
from IPython.display import display
from sklearn.model_selection import train_test_split
import tensorflow.keras.optimizers as tko,tensorflow.keras.layers as tkl
np.set_printoptions(precision=6)
from IPython.display import HTML
HTML('<style>.sagecell_input {text-shadow:4px 4px 4px #aaa;}</style>')
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
def preprocess(x):    
    x=(x-.5)*2; return np.clip(x,-int(1),int(1))
def deprocess(x,img_size):
    x=(x/2+.5)*255; x=np.clip(x,int(0),int(255))
    x=np.uint8(x); return x.reshape(img_size,img_size)
def latent_samples(n_samples,sample_size):
    return np.random.normal(
        loc=int(0),scale=int(1),size=(n_samples,sample_size))
def display_images(generated_images,img_size):
    n_images=len(generated_images)
    rows=int(4); cols=n_images//rows    
    pl.figure(figsize=(cols,rows))
    for i in range(n_images):
        img=deprocess(generated_images[i],img_size)
        pl.subplot(rows,cols,i+int(1))
        pl.imshow(img,cmap=pl.cm.Greys)
        pl.xticks([]); pl.yticks([])
    pl.tight_layout(); pl.show()
</script></div><br/> 
    <h2>‚úíÔ∏è&nbsp;Step 1. Loading and Preprocessing the Data</h2>       
<div class='linked'><script type='text/x-sage'>
path='https://raw.githubusercontent.com/OlgaBelitskaya/data_kitchen/main/'
zf='Letters32.h5'; input_file=urllib.request.urlopen(path+zf)
output_file=open(zf,'wb'); output_file.write(input_file.read())
output_file.close(); input_file.close()
with h5py.File(zf,'r') as f:
    keys=list(f.keys())
    pretty_print('file keys: '+', '.join(keys))
    images=np.array(f[keys[int(0)]])
    labels=np.array(f[keys[int(1)]])
    names=[[el.decode('utf-8') for el in f[keys[i]]]
        for i in range(int(2),len(keys))]
    f.close()
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
images=images[labels[int(2),:]==0]
labels=labels[:,labels[int(2),:]==0][int(1),:]
N=int(5000); sample_size=int(12)
img_size=int(20); latent_size=int(128)
latent_sample_in=latent_samples(int(1),img_size**2)
latent_sample_out=latent_samples(int(1),latent_size)
images=tf.image.resize(images[:N],[img_size,img_size]).numpy()
gray_images=np.dot(images[...,:3],[.299,.587,.114])
pl.figure(figsize=(2,3))
randi=np.random.randint(int(.9*N))
img=np.array(gray_images[randi])
pl.imshow(img.astype(float),cmap=pl.cm.Greys)
pl.tight_layout(); pl.title(labels[randi]); pl.show()
gray_images=gray_images.reshape(N,img_size**2)
gray_images.shape,gray_images.dtype
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
pl.figure(figsize=(2,3))
img0=np.squeeze(latent_sample_in).reshape(img_size,img_size)
pl.imshow(img0,cmap=pl.cm.Greys)
pl.tight_layout(); pl.show()
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
shuffle_ids=np.arange(N)
np.random.RandomState(12).shuffle(shuffle_ids)
gray_images=gray_images[shuffle_ids]
X_train_real,X_test_real=train_test_split(gray_images,test_size=.1)
X_train_real=preprocess(X_train_real)
X_test_real=preprocess(X_test_real)
display_images(X_train_real[:sample_size],img_size)
del images,labels,gray_images
X_train_real.shape,X_test_real.shape
</script></div><br/>
      <h2>‚úíÔ∏è &nbsp; Keras GAN</h2>
<a href='https://github.com/naokishibuya/deep-learning/blob/master/python/gan_mnist.ipynb'>
&#x1F300; &nbsp; "Using GAN for Generating Hand-written Digit Images" by Naoki Shibuya</a><br/>
A Simple Example<br/>
<div class='linked'><script type='text/x-sage'>
discriminator=tf.keras.Sequential(
    [tkl.Dense(int(512),input_shape=(img_size**2,)),
     tkl.LeakyReLU(alpha=.01),
     tkl.Dense(int(1)),
     tkl.Activation('sigmoid')],name='discriminator')
discriminator.summary()
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
fig=pl.figure(figsize=(4,3)); ax=fig.add_subplot(121)
img=X_train_real[randi].reshape(int(1),img_size**2)
ax.set_title(discriminator.predict(img))
ax.imshow(img.reshape(img_size,img_size),cmap=pl.cm.Greys)
ax=fig.add_subplot(122)
ax.set_title(discriminator.predict(img0.reshape(int(1),img_size**2)))
ax.imshow(img0,cmap=pl.cm.Greys)
pl.tight_layout(); pl.show()
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
generator=tf.keras.Sequential(
    [tkl.Dense(int(512),input_shape=(latent_size,)),
     tkl.LeakyReLU(alpha=.01),
     tkl.Dense(img_size**2),
     tkl.Activation('tanh')],name='generator')
generator.summary()
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
pl.figure(figsize=(2,3))
generated_latent_sample=generator.predict(latent_sample_out)
pl.title(discriminator.predict(generated_latent_sample))
pl.imshow(generated_latent_sample.reshape(img_size,img_size),
          cmap=pl.cm.Greys)
pl.tight_layout(); pl.show()
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
gan=tf.keras.Sequential([generator,discriminator]); gan.summary()
</script></div><br/>
Build a GAN Model<br/>
<div class='linked'><script type='text/x-sage'>
def trainable(model,trainable):
    for layer in model.layers: layer.trainable=trainable
def simple_GAN(latent_size,img_size,g_hidden_size,d_hidden_size, 
               leaky_alpha,g_learning_rate,d_learning_rate):    
    tf.keras.backend.clear_session()    
    generator=tf.keras.Sequential(
        [tkl.Dense(g_hidden_size,input_shape=(latent_size,)),
         tkl.LeakyReLU(alpha=leaky_alpha),
         tkl.Dense(img_size**2),
         tkl.Activation('tanh')],name='generator')    
    discriminator=tf.keras.Sequential(
        [tkl.Dense(d_hidden_size,input_shape=(img_size**2,)),
         tkl.LeakyReLU(alpha=leaky_alpha),
         tkl.Dense(int(1)),
         tkl.Activation('sigmoid')],name='discriminator')        
    gan=tf.keras.Sequential([generator,discriminator])    
    discriminator.compile(
        optimizer=tko.Adam(lr=d_learning_rate),loss='binary_crossentropy')
    gan.compile(
        optimizer=tko.Adam(lr=g_learning_rate),loss='binary_crossentropy')   
    return gan,generator,discriminator
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
latent_size    =int(128)     
g_hidden_size  =int(512)  # generator
d_hidden_size  =int(512)  # discriminator
leaky_alpha    =float(.02)
g_learning_rate=float(.0002) # generator
d_learning_rate=float(.0002)  # discriminator
epochs         =int(25)
batch_size     =int(64)      
valid_size     =int(16)     
smooth         =float(.1)
def real_fake_labels(size):
    return np.ones([size,int(1)]),np.zeros([size,int(1)])
y_real5,y_fake5=real_fake_labels(5)
print('Real\n',y_real5,'\nFake\n',y_fake5)
y_train_real,y_train_fake=real_fake_labels(batch_size)
y_valid_real,y_valid_fake=real_fake_labels(valid_size)
gan,generator,discriminator=\
simple_GAN(latent_size,img_size,g_hidden_size,d_hidden_size,
           leaky_alpha,g_learning_rate,d_learning_rate)
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
losses=[]
for e in range(epochs):
    for i in range(len(X_train_real)//batch_size):
        # real images
        X_batch_real=X_train_real[i*batch_size:(i+1)*batch_size]        
        # latent samples and generated letter images
        batch_latent_samples=latent_samples(batch_size,latent_size)
        X_batch_fake=generator.predict_on_batch(batch_latent_samples)        
        # train the discriminator to detect real and fake images
        trainable(discriminator,True)
        discriminator.train_on_batch(X_batch_real,y_train_real*(1.-smooth))
        discriminator.train_on_batch(X_batch_fake,y_train_fake)
        # train the generator via GAN
        trainable(discriminator,False)
        gan.train_on_batch(batch_latent_samples,y_train_real)    
    # evaluate
    X_valid_real=X_test_real[np.random.choice(
        len(X_test_real),valid_size,replace=False)]    
    valid_latent_samples=latent_samples(valid_size,latent_size)
    X_valid_fake=generator.predict_on_batch(valid_latent_samples)
    d_loss=discriminator.test_on_batch(X_valid_real,y_valid_real)
    d_loss+=discriminator.test_on_batch(X_valid_fake,y_valid_fake)
    g_loss=gan.test_on_batch(valid_latent_samples,y_valid_real)     
    losses.append((d_loss,g_loss))
    st='Epoch: %d/%d | Discriminator Loss: %.4f | '+\
       'Generator Loss: %.4f | DL > GL: %s'
    if (e+int(1))%int(10)==int(0):
        print(st%((e+int(1),epochs,d_loss,g_loss,d_loss>g_loss)))
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
latent_examples=latent_samples(sample_size,latent_size)
generated_letters=generator.predict(latent_examples)
display_images(generated_letters,img_size)
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
def display_loss(losses,n):
    indices=[i*n for i in range(len(losses)//n)]
    n_losses=np.array(losses)[indices,:]    
    pl.figure(figsize=(9,4))
    pl.plot(n_losses.T[int(0)],'-o',c='#37c9e1',
            lw=int(1),label='Discriminator')
    pl.plot(n_losses.T[1],'-o',c='#39d4be',
            lw=int(1),label='Generator')
    pl.title('Training Loss Functions')
    pl.legend(); pl.tight_layout(); pl.grid(); pl.show()
display_loss(losses,int(3))
</script></div><br/>
  </body>
</html>      
