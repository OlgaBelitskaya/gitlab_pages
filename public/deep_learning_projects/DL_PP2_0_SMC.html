<!DOCTYPE HTML>
<html>
  <head>
    <meta charset='utf-8'>
    <meta name='viewport' content='width=device-width'>
    <title>üèô DL PP2_0 SMC</title>
    <script src='https://sagecell.sagemath.org/static/embedded_sagecell.js'></script>
    <script>$(function(){
      sagecell.makeSagecell(
        {inputLocation:'div.linked',linked:true,evalButtonText:'run linked cells'}); });
    </script>
  </head>
  <style>
    @import 'https://fonts.googleapis.com/css?family=Akronim|Lobster';
    h1,h2,th {color:#348ABD; font-family:Akronim; font-size:120%; text-shadow:4px 4px 4px #aaa;}
    p,a {color:slategray; font-family:Lobster; font-size:120%; text-shadow:4px 4px 4px #aaa;}
    .sagecell .CodeMirror-scroll {min-height:3em; max-height:70em;}
    body {margin:5px 5px 5px 15px;}
  </style>  
  <body>
    <h1>üìë &nbsp; Deep Learning. Practice Project 2_0: One-Label & Multi-Label Classification</h1>
<a href='https://olgabelitskaya.gitlab.io/index.html'>&#x1F300; &nbsp; Homepage &nbsp; &nbsp;</a>
<a href='https://olgabelitskaya.gitlab.io/deep_learning_projects/index.html'>&#x1F300; &nbsp; Project List &nbsp; &nbsp;</a>
<a href='https://olgabelitskaya.github.io/README.html'>&#x1F300; &nbsp; GitHub Pages &nbsp; &nbsp;</a>
<a href='https://olgabelitskaya.gitlab.io/deep_learning_projects/DL_PP1_0_SMC.html'>
&#x1F300; &nbsp; Previous &nbsp; &nbsp;</a>
<a href='https://olgabelitskaya.gitlab.io/deep_learning_projects/DL_PP2_1_SMC.html'>
&#x1F300; &nbsp; Addition 1 &nbsp; &nbsp;</a>
<a href='https://olgabelitskaya.gitlab.io/deep_learning_projects/DL_PP2_2_SMC.html'>
&#x1F300; &nbsp; Addition 2 &nbsp; &nbsp;</a>
<a href='https://olgabelitskaya.gitlab.io/deep_learning_projects/DL_PP3_0_SMC.html'>
&#x1F300; &nbsp; Next &nbsp; &nbsp;</a><br/>
<a href='https://www.instagram.com/olga.belitskaya/'>&#x1F300; &nbsp; Instagram Posts &nbsp; &nbsp;</a>
<a href='https://www.pinterest.ru/olga_belitskaya/code-style/'>&#x1F300; &nbsp; Pinterest Posts</a><br/>
For this project, I have created the dataset of color images (32x32x3) with 33 handwritten Russian letters.<br/>
There are four types of letter backgrounds here. <br/>
They are labeled in this dataset as well.<br/>
<div class='linked'><script type='text/x-sage'>
import urllib,os; from IPython.display import HTML
file_path='https://raw.githubusercontent.com/OlgaBelitskaya/data/main/symbols/'
lf=['00_00_00_00_001.png','00_00_02_01_001.png','00_00_01_02_001.png','00_00_00_03_001.png']
for f in lf:
    input_file=urllib.request.urlopen(file_path+f)
    output_file=open(f,'wb')
    output_file.write(input_file.read())
    output_file.close(); input_file.close()
url='https://sagecell.sagemath.org/kernel/'
url+=os.getcwd()[14:]+'/files/'
HTML("""<style>@import 
'https://fonts.googleapis.com/css?family=Akronim|Aladin';
.sagecell_input {text-shadow:4px 4px 4px #aaa;}</style>
<table style='width:50%; background-color:ghostwhite; font-family:Aladin; font-size:120%;'>
<tr style='font-family:Akronim;'><th><center>Background</center></th>
<th><center>Image</center></th></tr>
<tr><td><center>single-colored paper</center></td><td><center>
<img width='50' height='50' src="""+url+lf[0]+""" alt='bg0'></center></td></tr>
<tr><td><center>striped paper</center></td><td><center>
<img width='50' height='50' src="""+url+lf[1]+""" alt='bg1'></center></td></tr>
<tr><td><center>squared paper</center></td><td><center>
<img width='50' height='50' src="""+url+lf[2]+""" alt='bg2'></center></td></tr>
<tr><td><center>graph paper</center></td><td><center>
<img width='50' height='50' src="""+url+lf[3]+""" alt='bg3'>
</center></td></tr></table>""")
</script></div><br/>
    <h2>‚úíÔ∏è&nbsp;Step 0. Importing Libraries and Defining Helpful Functions</h2>
<div class='linked'><script type='text/x-sage'>
import warnings; warnings.filterwarnings('ignore')
import h5py,urllib,tensorflow as tf
import pandas as pd,numpy as np,pylab as pl,seaborn as sn
from IPython.display import display
from tensorflow.keras.preprocessing import image as tkimg
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.ensemble import RandomForestClassifier
import tensorflow.keras.callbacks as tkc,tensorflow.keras.layers as tkl
np.set_printoptions(precision=6)
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
def h5file2data(h5file,cmap,img_size):
    with h5py.File(h5file,'r') as f:
        keys=list(f.keys())
        pretty_print('file keys: '+', '.join(keys))
        images=np.array(f[keys[int(0)]])
        labels=np.array(f[keys[int(1)]])
        names=[[el.decode('utf-8') for el in f[keys[i]]]
               for i in range(int(2),len(keys))]
        f.close()
    N=images.shape[int(0)]; n=int(.1*N) 
    shuffle_ids=np.arange(N)
    np.random.RandomState(12).shuffle(shuffle_ids)
    images=images[shuffle_ids]
    images=tf.image.resize(images,[img_size,img_size]).numpy()
    labels=np.array([labels[i][shuffle_ids] 
                     for i in range(labels.shape[int(0)])])
    x_test,x_valid,x_train=images[:n],images[n:2*n],images[2*n:]
    y_test,y_valid,y_train=labels[:,:n],labels[:,n:2*n],labels[:,2*n:]
    pretty_print('data outputs: ')
    df=pd.DataFrame([[x_train.shape,x_valid.shape,x_test.shape],
                     [x_train.dtype,x_valid.dtype,x_test.dtype],
                     [y_train.shape,y_valid.shape,y_test.shape],
                     [y_train.dtype,y_valid.dtype,y_test.dtype]],
                    columns=['train','valid','test'],
                    index=['image shape','image type',
                           'label shape','label type'])
    display(df)
    pretty_print('distribution of labels: ')
    idx=['labels %d'%(i+int(1)) for i in range(labels.shape[int(0)])]
    df=pd.DataFrame(labels,index=idx).T
    for i in range(labels.shape[int(0)]):
        df['name %d'%(i+int(1))]=[names[i][l] for l in labels[i]]
    fig=pl.figure(figsize=(9,6))    
    for i in range(labels.shape[int(0)]):
        ax=fig.add_subplot(labels.shape[int(0)],int(1),i+int(1))
        sn.countplot(x='name %s'%(i+1),data=df,palette=cmap,alpha=.5,ax=ax)
    pl.tight_layout(); pl.show()       
    return [names,x_train,x_valid,x_test,y_train,y_valid,y_test]
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
def display_images(images,labels,names,n):
    fig=pl.figure(figsize=(9,n/1.5))
    randch=np.random.choice(images.shape[0],size=n,replace=False)
    for i,idx in enumerate(randch):
        ax=fig.add_subplot(n//3,3,i+1,xticks=[],yticks=[])
        ax.imshow(images[idx],cmap='Greys')
        label=[labels[:,idx]]
        name=[names[i][labels[i][idx]] for i in range(labels.shape[0])]
        ti='{} \n {}'.format(str(label),str(name))
        ax.set_title(ti,fontsize=8)
    pl.tight_layout(); pl.show()
def keras_history_plot(fit_history,fig_size,color):
    keys=list(fit_history.history.keys())
    list_history=[fit_history.history[keys[i]] for i in range(len(keys))]
    dfkeys=pd.DataFrame(list_history).T
    dfkeys.columns=keys
    fig=pl.figure(figsize=(fig_size,fig_size/1.5))
    ax1=fig.add_subplot(2,1,1)
    dfkeys.iloc[:,[int(0),int(2)]].plot(ax=ax1,color=['slategray',color])
    pl.grid(); ax2=fig.add_subplot(2,1,2)
    dfkeys.iloc[:,[int(1),int(3)]].plot(ax=ax2,color=['slategray',color])
    pl.grid(); pl.tight_layout(); pl.show()
</script></div><br/> 
    <h2>‚úíÔ∏è&nbsp;Step 1. Loading and Preprocessing the Data</h2>       
<div class='linked'><script type='text/x-sage'>
path='https://raw.githubusercontent.com/OlgaBelitskaya/data_kitchen/main/'
zf='Letters32.h5'; input_file=urllib.request.urlopen(path+zf)
output_file=open(zf,'wb'); output_file.write(input_file.read())
output_file.close(); input_file.close()
img_size=int(20); n1=int(3000); n2=int(300)
[names,x_train,x_valid,x_test,y_train,y_valid,y_test]=\
h5file2data(zf,'Pastel1',img_size)
os.remove(zf)
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
gx_train=np.dot(x_train[...,:3],[.299,.587,.114])
gx_valid=np.dot(x_valid[...,:3],[.299,.587,.114])
gx_test=np.dot(x_test[...,:3],[.299,.587,.114])
display_images(x_train,y_train,names,3)
display_images(gx_test,y_test,names,3)
gx_train=gx_train.reshape(-int(1),img_size,img_size,int(1))
gx_valid=gx_valid.reshape(-int(1),img_size,img_size,int(1))
gx_test=gx_test.reshape(-int(1),img_size,img_size,int(1))
</script></div><br/>
      <h2>‚úíÔ∏è &nbsp; Step 2. One-Label Classification Models</h2>
<p>Color Images</p>
<div class='linked'><script type='text/x-sage'>
def model():
    model=tf.keras.Sequential()
    model.add(tkl.Conv2D(
       int(16),(int(3),int(3)),padding='same',
       input_shape=x_train.shape[int(1):]))
    model.add(tkl.LeakyReLU(alpha=.02))   
    model.add(tkl.MaxPooling2D(pool_size=(int(2),int(2))))
    model.add(tkl.Dropout(.2))
    model.add(tkl.Conv2D(int(48),(int(3),int(3))))
    model.add(tkl.LeakyReLU(alpha=.02))  
    model.add(tkl.MaxPooling2D(pool_size=(int(2),int(2))))
    model.add(tkl.Dropout(.2))
    model.add(tkl.GlobalMaxPooling2D())  
    model.add(tkl.Dense(int(256)))
    model.add(tkl.LeakyReLU(alpha=.02))
    model.add(tkl.Dropout(.5))     
    model.add(tkl.Dense(int(33),activation='softmax'))
    model.compile(loss='sparse_categorical_crossentropy',
                  optimizer='adam',metrics=['accuracy'])   
    return model
model=model()
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
checkpointer=tkc.ModelCheckpoint(
    filepath='/tmp/checkpoint',verbose=int(0),save_weights_only=True,
    monitor='val_accuracy',mode='max',save_best_only=True)
lr_reduction=tkc.ReduceLROnPlateau(
    monitor='val_loss',patience=int(5),verbose=int(0),factor=.8)
history=model.fit(
    x_train[:n1],y_train[int(1),:n1],epochs=int(12),batch_size=int(64),
    verbose=int(2),validation_data=(x_valid[:n2],y_valid[int(1),:n2]),
    callbacks=[checkpointer,lr_reduction])
</script></div><br/>  
<div class='linked'><script type='text/x-sage'>
keras_history_plot(history,9,'#348ABD')
model.load_weights('/tmp/checkpoint')
pretty_print(model.evaluate(
    x_test[:n2],y_test[int(1),:n2],verbose=int(0)))
</script></div><br/>
<p>Grayscale Images</p><br/>
<div class='linked'><script type='text/x-sage'>
def gray_model():
    model=tf.keras.Sequential()    
    model.add(tkl.Conv2D(
        int(16),(int(3),int(3)),padding='same', 
        input_shape=gx_train.shape[int(1):]))
    model.add(tkl.Activation('relu'))    
    model.add(tkl.MaxPooling2D(pool_size=(int(2),int(2))))
    model.add(tkl.Dropout(.2))
    model.add(tkl.Conv2D(int(48),(int(3),int(3))))
    model.add(tkl.Activation('relu'))    
    model.add(tkl.MaxPooling2D(pool_size=(int(2),int(2))))
    model.add(tkl.Dropout(.2))   
    model.add(tkl.GlobalMaxPooling2D())    
    model.add(tkl.Dense(int(256),activation='relu'))
    model.add(tkl.Dropout(.5))        
    model.add(tkl.Dense(int(33),activation='softmax'))   
    model.compile(loss='sparse_categorical_crossentropy', 
                  optimizer='rmsprop',metrics=['accuracy'])
    return model
gray_model=gray_model() 
</script></div><br/> 
<div class='linked'><script type='text/x-sage'>
checkpointer=tkc.ModelCheckpoint(
    filepath='/tmp/checkpoint',verbose=int(0),save_weights_only=True,
    monitor='val_accuracy',mode='max',save_best_only=True)
lr_reduction=tkc.ReduceLROnPlateau(
    monitor='val_loss',patience=int(5),verbose=int(0),factor=.8)
history=gray_model.fit(
    gx_train[:n1],y_train[int(1),:n1],epochs=int(12),batch_size=int(64),
    verbose=int(2),validation_data=(gx_valid[:n2],y_valid[int(1),:n2]),
    callbacks=[checkpointer,lr_reduction])
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
keras_history_plot(history,9,'#348ABD')
gray_model.load_weights('/tmp/checkpoint')
pretty_print(gray_model.evaluate(
    gx_test[:n2],y_test[int(1),:n2],verbose=int(0)))
</script></div><br/>
      <h2>‚úíÔ∏è &nbsp; Step 3. Multi-Label Classification Models</h2>      
<div class='linked'><script type='text/x-sage'>
def multi_model():    
    model_input=tkl.Input(shape=(img_size,img_size,int(3)))
    x=tkl.BatchNormalization()(model_input)
    x=tkl.Conv2D(int(32),(int(3),int(3)),padding='same')(model_input)
    x=tkl.LeakyReLU(alpha=.02)(x)
    x=tkl.MaxPooling2D(pool_size=(int(2),int(2)))(x)    
    x=tkl.Dropout(.2)(x)   
    x=tkl.Conv2D(int(96),(int(3),int(3)),padding='same')(x)
    x=tkl.LeakyReLU(alpha=.02)(x)
    x=tkl.MaxPooling2D(pool_size=(int(2),int(2)))(x)    
    x=tkl.Dropout(.2)(x)             
    x=tkl.GlobalMaxPooling2D()(x)   
    x=tkl.Dense(int(512))(x)
    x=tkl.LeakyReLU(alpha=.02)(x)
    x=tkl.Dropout(.25)(x)   
    x=tkl.Dense(int(128))(x)  
    x=tkl.LeakyReLU(alpha=.02)(x)
    x=tkl.Dropout(.25)(x)    
    y1=tkl.Dense(int(33),activation='softmax')(x)
    y2=tkl.Dense(int(4),activation='softmax')(x)    
    model=tf.keras.Model(inputs=model_input,outputs=[y1,y2])
    model.compile(loss='sparse_categorical_crossentropy',
                  optimizer='nadam',metrics=['accuracy'])
    return model
multi_model=multi_model()
multi_model.summary()
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
checkpointer=tkc.ModelCheckpoint(
    filepath='/tmp/checkpoint',verbose=int(0),save_weights_only=True,
    monitor='val_loss',mode='min',save_best_only=True)
lr_reduction=tkc.ReduceLROnPlateau(
    monitor='val_loss',patience=int(5),verbose=int(0),factor=.8)
history=multi_model.fit(
    x_train[:n1],[y_train[int(1),:n1],y_train[int(2),:n1]],
    epochs=int(12),batch_size=int(64),verbose=int(2),
    validation_data=(x_valid[:n2],[y_valid[int(1),:n2],y_valid[int(2),:n2]]),
    callbacks=[checkpointer,lr_reduction])
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
multi_model.load_weights('/tmp/checkpoint')
pretty_print(multi_model.evaluate(x_test[:n2],\
[y_test[int(1),:n2],y_test[int(2),:n2]],verbose=int(0)))
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
def gray_multi_model():    
    model_input=tkl.Input(shape=(img_size,img_size,int(1)))
    x=tkl.BatchNormalization()(model_input)
    x=tkl.Conv2D(int(16),(int(3),int(3)),padding='same')(model_input)
    x=tkl.LeakyReLU(alpha=.2)(x)
    x=tkl.MaxPooling2D(pool_size=(int(2),int(2)))(x)    
    x=tkl.Dropout(.2)(x)   
    x=tkl.Conv2D(int(48),(int(3),int(3)),padding='same')(x) 
    x=tkl.LeakyReLU(alpha=.02)(x)
    x=tkl.MaxPooling2D(pool_size=(int(2),int(2)))(x)    
    x=tkl.Dropout(.25)(x)             
    x=tkl.GlobalMaxPooling2D()(x)    
    x=tkl.Dense(int(512))(x) 
    x=tkl.LeakyReLU(alpha=.02)(x)
    x=tkl.Dropout(.25)(x)     
    y1=tkl.Dense(int(33),activation='softmax')(x)
    y2=tkl.Dense(int(4),activation='softmax')(x)      
    model=tf.keras.Model(inputs=model_input,outputs=[y1,y2])
    model.compile(loss='sparse_categorical_crossentropy',
                  optimizer='rmsprop',metrics=['accuracy'])      
    return model
gray_multi_model=gray_multi_model()
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
checkpointer=tkc.ModelCheckpoint(
    filepath='/tmp/checkpoint',verbose=int(0),save_weights_only=True,
    monitor='val_loss',mode='min',save_best_only=True)
lr_reduction=tkc.ReduceLROnPlateau(
    monitor='val_loss',patience=int(5),verbose=int(0),factor=.8)
history=gray_multi_model.fit(
    gx_train[:n1],[y_train[int(1),:n1],y_train[int(2),:n1]], 
    validation_data=(gx_valid[:n2],[y_valid[int(1),:n2],y_valid[int(2),:n2]]), 
    epochs=int(12),batch_size=int(64),verbose=int(2), 
    callbacks=[checkpointer,lr_reduction])
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
gray_multi_model.load_weights('/tmp/checkpoint')
pd.DataFrame(gray_multi_model.evaluate(gx_test[:n2],\
[y_test[int(1),:n2],y_test[int(2),:n2]],verbose=int(0)))
</script></div><br/>
  </body>
</html>      
