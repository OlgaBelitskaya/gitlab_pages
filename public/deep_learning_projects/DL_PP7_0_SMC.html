<!DOCTYPE HTML>
<html>
  <head>
    <meta charset='utf-8'>
    <meta name='viewport' content='width=device-width'>
    <title>üèô DL PP7_0 SMC</title>
    <script src='https://sagecell.sagemath.org/static/embedded_sagecell.js'></script>
    <script>$(function(){
      sagecell.makeSagecell(
        {inputLocation:'div.linked',linked:true,evalButtonText:'run linked cells'});});
    </script>
  </head>
  <style>
    @import 'https://fonts.googleapis.com/css?family=Akronim|Lobster';
    h1,h2,th {color:#348ABD; font-family:Akronim; font-size:120%; text-shadow:4px 4px 4px #aaa;}
    p,a {color:slategray; font-family:Lobster; font-size:120%; text-shadow:4px 4px 4px #aaa;}
    .sagecell .CodeMirror-scroll {min-height:3em; max-height:70em;}
    body {margin:5px 5px 5px 15px;}
  </style>  
  <body>
    <h1>üìë &nbsp; Deep Learning. Practice Project 7_0: Simple Neural Networks for Image Classification</h1>
<a href='https://olgabelitskaya.gitlab.io/index.html'>&#x1F300; &nbsp; Homepage &nbsp; &nbsp;</a>
<a href='https://olgabelitskaya.gitlab.io/deep_learning_projects/index.html'>
&#x1F300; &nbsp; Project List &nbsp; &nbsp;</a>
<a href='https://olgabelitskaya.github.io/README.html'>&#x1F300; &nbsp; GitHub Pages &nbsp; &nbsp;</a>
<a href='https://olgabelitskaya.gitlab.io/deep_learning_projects/DL_PP6_0_SMC.html'>
&#x1F300; &nbsp; Previous &nbsp; &nbsp;</a>
<a href='https://olgabelitskaya.gitlab.io/deep_learning_projects/DL_PP7_1_SMC.html'>
&#x1F300; &nbsp; Addition 1 &nbsp; &nbsp;</a>
<a href='https://olgabelitskaya.gitlab.io/deep_learning_projects/DL_PP8_0_SMC.html'>
&#x1F300; &nbsp; Next &nbsp; &nbsp;</a><br/>
<a href='https://www.instagram.com/olga.belitskaya/'>&#x1F300; &nbsp; Instagram Posts &nbsp; &nbsp;</a>
<a href='https://www.pinterest.ru/olga_belitskaya/code-style/'>&#x1F300; &nbsp; Pinterest Posts</a><br/>
In this project, we'll classify images from the dataset
<a href='https://www.kaggle.com/olgabelitskaya/white-flowers'>White Flowers</a>.<br/>
The content is about 500-600 images (128x128x3) with photos of white flowers
stored in the file of <i>Hierarchical Data Format (HDF5)</i>.<br/>
In the original dataset, photo files have the extension PNG and they are labeled by file prefixes.<br/>
We'll preprocess the images, represent their examples, then train neural networks.<br/> 
We are going to apply 
<a href='https://keras.io/'>Keras: a Python Deep Learning Library</a><br/>
and
<a href='https://pytorch.org/'>PyTorch: an Open Source Machine Learning Framework</a>.<br/>
    <h2>‚úíÔ∏è &nbsp; Code Modules & Settings</h2>      
<div class='linked'><script type='text/x-sage'>
!python3 -m pip install --upgrade pip --user --quiet --no-warn-script-location
!python3 -m pip install torch==1.8.0 --user --quiet --no-warn-script-location
!python3 -m pip install torchvision==0.9.0 --user --quiet --no-warn-script-location
path='/home/sc_work/.sage/local/lib/python3.9/site-packages'
import sys,warnings; sys.path.append(path); warnings.filterwarnings('ignore')
import os,h5py,urllib,torch,pandas as pd,numpy as np
import tensorflow as tf,pylab as pl
import tensorflow.keras.layers as tkl
import tensorflow.keras.callbacks as tkc
from torch.utils.data import DataLoader as tdl
from torch.utils.data import Dataset as tds
from torchvision import transforms,utils,models
import torch.nn.functional as tnnf,torch.nn as tnn
dev=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
from IPython.core.magic import register_line_magic
from IPython.display import HTML
HTML('<style>.sagecell_input {text-shadow:4px 4px 4px #aaa;}</style>')
</script></div><br/>      
    <h2>‚úíÔ∏è &nbsp; Data Loading</h2> 
<div class='linked'><script type='text/x-sage'>
file_path='https://raw.githubusercontent.com/OlgaBelitskaya/data_kitchen/main/'
file_name='WhiteFlowers128.h5'; img_size=int(48)
def get_data(file_path,file_name,img_size):
    input_file=urllib.request.urlopen(file_path+file_name)
    output_file=open(file_name,'wb')
    output_file.write(input_file.read())
    output_file.close(); input_file.close()
    with h5py.File(file_name,'r') as f:
        keys=list(f.keys())
        pretty_print(html(
            '<p>file keys: '+', '.join(keys)+'</p>'))
        images=np.array(f[keys[0]])
        images=tf.image.resize(images,[img_size,img_size]).numpy()
        labels=np.array(f[keys[1]])
        names=[el.decode('utf-8') for el in f[keys[2]]]
        f.close()
    pretty_print(html('<p>%s'%names+'</p>'))
    return images,labels,names
images,labels,names=get_data(file_path,file_name,img_size)
</script></div><br/>
    <h2>‚úíÔ∏è &nbsp; Data Processing</h2>  
<div class='linked'><script type='text/x-sage'>
N=labels.shape[0]; n=int(.1*N)
num_classes=len(names); start=int(100) 
shuffle_ids=np.arange(N)
np.random.RandomState(12).shuffle(shuffle_ids)
images=images[shuffle_ids]; labels=labels[shuffle_ids]
x_test,x_valid,x_train=images[:n],images[n:2*n],images[2*n:]
y_test,y_valid,y_train=labels[:n],labels[n:2*n],labels[2*n:]
df=pd.DataFrame(
    [[x_train.shape,x_valid.shape,x_test.shape],
     [x_train.dtype,x_valid.dtype,x_test.dtype],
     [y_train.shape,y_valid.shape,y_test.shape],
     [y_train.dtype,y_valid.dtype,y_test.dtype]],
    columns=['train','valid','test'],
    index=['image shape','image type','label shape','label type'])
def display_imgs(images,labels,names,start):
    fig=pl.figure(figsize=(6,3)); n=randint(0,start-1)
    for i in range(n,n+6):
        ax=fig.add_subplot(2,3,i-n+1,xticks=[],yticks=[])
        ax.set_title(
            names[labels[i]],color='slategray',fontdict={'fontsize':'large'})
        ax.imshow((images[i]))
    pl.tight_layout(); pl.show()
display_imgs(images,labels,names,start); display(df)
</script></div><br/>
    <h2>‚úíÔ∏è &nbsp; Keras Models</h2>
<div class='linked'><script type='text/x-sage'>
def keras_history_plot(fit_history,fig_size,color):
    keys=list(fit_history.history.keys())
    list_history=[fit_history.history[keys[i]] 
                  for i in range(len(keys))]
    dfkeys=pd.DataFrame(list_history).T
    dfkeys.columns=keys
    fig=pl.figure(figsize=(fig_size,fig_size//2))
    ax1=fig.add_subplot(2,1,1)
    dfkeys.iloc[:,[int(0),int(2)]].plot(
        ax=ax1,color=['slategray',color])
    pl.grid(); ax2=fig.add_subplot(2,1,2)
    dfkeys.iloc[:,[int(1),int(3)]].plot(
        ax=ax2,color=['slategray',color])
    pl.grid(); pl.show()
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
def cnn_model(num_classes):
    model=tf.keras.Sequential(); dr=float(.25)
    model.add(tkl.Conv2D(int(32),(int(3),int(3)),padding='same', 
                         input_shape=x_train.shape[int(1):]))
    model.add(tkl.LeakyReLU(alpha=.02))
    model.add(tkl.MaxPooling2D(pool_size=(int(2),int(2))))
    model.add(tkl.Dropout(dr))
    model.add(tkl.GlobalMaxPooling2D())    
    model.add(tkl.Dense(int(512)))
    model.add(tkl.LeakyReLU(alpha=.02))
    model.add(tkl.Dropout(2*dr))      
    model.add(tkl.Dense(num_classes))
    model.add(tkl.Activation('softmax'))
    model.compile(loss='sparse_categorical_crossentropy', 
                  optimizer='nadam',metrics=['accuracy'])    
    return model
model=cnn_model(num_classes)
checkpointer=tkc.ModelCheckpoint(
    filepath='/tmp/checkpoint',verbose=int(2),save_weights_only=True,
    monitor='val_accuracy',mode='max',save_best_only=True)
history=model.fit(
    x_train,y_train,batch_size=int(16),epochs=int(5),verbose=int(2),
    validation_data=(x_valid,y_valid),callbacks=[checkpointer])
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
model.load_weights('/tmp/checkpoint')
print('[loss, accuracy] => %s'%\
      str(model.evaluate(x_test,y_test,verbose=int(0))))
keras_history_plot(history,8,'#348ABD')
</script></div><br/>      
<div class='linked'><script type='text/x-sage'>
input_shape=int(3)*img_size**int(2)
def mlp_model(num_classes,input_shape=input_shape):
    model=tf.keras.Sequential()
    model.add(tkl.Dense(int(128),input_shape=(input_shape,)))
    model.add(tkl.LeakyReLU(alpha=.02)) 
    model.add(tkl.BatchNormalization()) 
    model.add(tkl.Dense(int(256)))
    model.add(tkl.LeakyReLU(alpha=.02)) 
    model.add(tkl.BatchNormalization())
    model.add(tkl.Dense(int(512)))
    model.add(tkl.LeakyReLU(alpha=.02))
    model.add(tkl.Dropout(float(.2)))     
    model.add(tkl.Dense(num_classes))
    model.add(tkl.Activation('softmax'))
    model.compile(loss='sparse_categorical_crossentropy', 
                  optimizer='nadam',metrics=['accuracy'])    
    return model
model=mlp_model(num_classes,input_shape)
checkpointer=tkc.ModelCheckpoint(
    filepath='/tmp/checkpoint',verbose=int(2),save_weights_only=True,
    monitor='val_accuracy',mode='max',save_best_only=True)
history=model.fit(
    x_train.reshape(-int(1),input_shape),y_train,
    batch_size=int(16),epochs=int(5),verbose=int(2),
    validation_data=(x_valid.reshape(-int(1),input_shape),y_valid),
    callbacks=[checkpointer])
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
model.load_weights('/tmp/checkpoint')
print('[loss, accuracy] => %s'%\
      str(model.evaluate(x_test.reshape(-int(1),input_shape),
                         y_test,verbose=int(0))))
keras_history_plot(history,8,'#348ABD')
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
input_shape=int(3)*img_size**int(2)
def rnn_model(num_classes,input_shape=input_shape):
    model=tf.keras.Sequential()
    model.add(tkl.LSTM(int(196),return_sequences=True,
                       input_shape=(int(1),input_shape)))
    model.add(tkl.LSTM(int(196))) 
    model.add(tkl.Dense(int(512)))
    model.add(tkl.LeakyReLU(alpha=float(.02)))
    model.add(tkl.Dropout(float(.2)))     
    model.add(tkl.Dense(num_classes))
    model.add(tkl.Activation('softmax'))
    model.compile(loss='sparse_categorical_crossentropy', 
                  optimizer='nadam',metrics=['accuracy'])    
    return model
model=rnn_model(num_classes,input_shape)
checkpointer=tkc.ModelCheckpoint(
    filepath='/tmp/checkpoint',verbose=int(2),save_weights_only=True,
    monitor='val_accuracy',mode='max',save_best_only=True)
history=model.fit(
    x_train.reshape(-int(1),int(1),input_shape),y_train,
    batch_size=int(16),epochs=int(3),verbose=int(2),
    validation_data=(x_valid.reshape(-int(1),int(1),input_shape),y_valid),
    callbacks=[checkpointer])
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
model.load_weights('/tmp/checkpoint')
print('[loss, accuracy] => %s'%\
      str(model.evaluate(x_test.reshape(-int(1),int(1),input_shape),
                         y_test,verbose=int(0))))
keras_history_plot(history,8,'#348ABD')
</script></div><br/>
    <h2>‚úíÔ∏è &nbsp; PyTorch Data</h2>
<div class='linked'><script type='text/x-sage'>      
class TData(tds):
    def __init__(self,x,y):   
        self.x=torch.tensor(x,dtype=torch.float32)
        self.y=torch.tensor(y,dtype=torch.int32)
    def __getitem__(self,index):
        img,lbl=self.x[index],self.y[index]
        return img,lbl
    def __len__(self):
        return self.y.shape[0]
batch_size2=int(8); img_size2=int(48)
n_train=batch_size2*(x_train.shape[0]//batch_size2)
x_train2=np.transpose(x_train,(0,3,1,2))[:n_train]
print(x_train2.mean(),x_train2.std())
n_valid=batch_size2*(x_valid.shape[0]//batch_size2)
x_valid2=np.transpose(x_valid,(0,3,1,2))[:n_valid]
n_test=batch_size2*(x_test.shape[0]//batch_size2)
x_test2=np.transpose(x_test,(0,3,1,2))[:n_test]
random_seed=23
train2=TData(x_train2,y_train[:n_train])
valid2=TData(x_valid2,y_valid[:n_valid])
test2=TData(x_test2,y_test[:n_test])
dataloaders={'train':tdl(dataset=train2,shuffle=True,batch_size=batch_size2), 
             'valid':tdl(dataset=valid2,shuffle=True,batch_size=batch_size2),
             'test':tdl(dataset=test2,shuffle=True,batch_size=batch_size2)}
del train2,valid2,test2
@register_line_magic
def display_data_imgs(data):
    global names
    for images,labels in dataloaders[data]:  
        print('image dimensions: %s'%str(images.shape))
        print('label dimensions: %s'%str(labels.shape))
        images=[np.transpose(images[i],(1,2,0)) 
                for i in range(len(images))]
        display_imgs(images,labels,names,int(1))
        break
%display_data_imgs valid
</script></div><br/>
    <h2>‚úíÔ∏è &nbsp; PyTorch Models</h2>   
<div class='linked'><script type='text/x-sage'>
tmodel=models.vgg19(pretrained=True,progress=False)
for param in tmodel.parameters(): param.requires_grad=False
tmodel.classifier[3].requires_grad=True
def model_acc(model,data_loader):
    correct_preds,num_examples=int(0),int(0)
    for features,targets in data_loader:
        features=features.to(dev)
        targets=targets.to(dev).long()
        logits=model(features)
        _,pred_labels=torch.max(logits,int(1))
        num_examples+=targets.size(int(0))
        correct_preds+=(pred_labels==targets).sum()        
    return correct_preds.float()/num_examples*int(100)
def epoch_loss(model,data_loader):
    model.eval()
    curr_loss,num_examples=float(0.),int(0)
    with torch.no_grad():
        for features,targets in data_loader:
            features=features.to(dev)
            targets=targets.to(dev).long()
            logits=model(features)
            loss=tnnf.cross_entropy(logits,targets,reduction='sum')
            num_examples+=targets.size(int(0))
            curr_loss+=loss
        return curr_loss/num_examples
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
@register_line_magic
def train_run(epochs):
    epochs=int(epochs)
    st1='epoch: %03d/%03d || batch: %03d/%03d || cost: %.4f'
    for epoch in range(epochs):
        tmodel.train()
        for batch_ids,(features,targets) \
        in enumerate(dataloaders['train']):        
            features=features.to(dev)
            targets=targets.to(dev).long()
            logits=tmodel(features)
            cost=tnnf.cross_entropy(logits,targets)
            optimizer.zero_grad(); cost.backward()
            optimizer.step()
            if not batch_ids%int(20):
                print(st1%(epoch+int(1),epochs,batch_ids,
                      len(dataloaders['train']),cost))
        tmodel.eval()
        with torch.set_grad_enabled(False):
            print('epoch: %03d/%03d'%(epoch+int(1),epochs))
            print('valid acc/loss: %.2f%%/%.2f'%\
                  (model_acc(tmodel,dataloaders['valid']),
                  epoch_loss(tmodel,dataloaders['valid'])))
tmodel.classifier[6]=tnn.Sequential(
    tnn.Linear(int(4096),int(256)),tnn.ReLU(),
    tnn.Dropout(float(.5)),tnn.Linear(int(256),num_classes))
tmodel=tmodel.to(dev)
optimizer=torch.optim.Adam(tmodel.parameters())
%train_run 1
</script></div><br/>
<div class='linked'><script type='text/x-sage'>      
tmodel.eval()
with torch.set_grad_enabled(False):
    print('test acc: %.2f%%'%model_acc(tmodel,dataloaders['test']))
</script></div><br/>
  </body>
</html>
