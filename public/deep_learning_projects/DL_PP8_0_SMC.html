<!DOCTYPE HTML>
<html>
  <head>
    <meta charset='utf-8'>
    <meta name='viewport' content='width=device-width'>
    <title>üèô DL PP8_0 SMC</title>
    <script src='https://sagecell.sagemath.org/static/embedded_sagecell.js'></script>
    <script>$(function(){
      sagecell.makeSagecell(
        {inputLocation:'div.linked',linked:true,evalButtonText:'run linked cells'});});
    </script>
  </head>
  <style>
    @import 'https://fonts.googleapis.com/css?family=Akronim|Lobster';
    h1,h2,th {color:#348ABD; font-family:Akronim; font-size:120%; text-shadow:4px 4px 4px #aaa;}
    p,a {color:slategray; font-family:Lobster; font-size:120%; text-shadow:4px 4px 4px #aaa;}
    .sagecell .CodeMirror-scroll {min-height:3em; max-height:70em;}
    body {margin:5px 5px 5px 15px;}
  </style>  
  <body>
    <h1>üìë &nbsp; Deep Learning. Practice Project 8_0: 
        Neural Networks for Classification of Drawings & Photo Images</h1>
<a href='https://olgabelitskaya.gitlab.io/index.html'>&#x1F300; &nbsp; Homepage &nbsp; &nbsp;</a>
<a href='https://olgabelitskaya.gitlab.io/deep_learning_projects/index.html'>
&#x1F300; &nbsp; Project List &nbsp; &nbsp;</a>
<a href='https://olgabelitskaya.github.io/README.html'>&#x1F300; &nbsp; GitHub Pages &nbsp; &nbsp;</a>
<a href='https://olgabelitskaya.gitlab.io/deep_learning_projects/DL_PP7_0_SMC.html'>
&#x1F300; &nbsp; Previous &nbsp; &nbsp;</a>
<a href='https://olgabelitskaya.gitlab.io/deep_learning_projects/DL_PP8_1_SMC.html'>
&#x1F300; &nbsp; Addition 1 &nbsp; &nbsp;</a>
<a href='https://olgabelitskaya.gitlab.io/deep_learning_projects/DL_PP8_2_SMC.html'>
&#x1F300; &nbsp; Addition 2 &nbsp; &nbsp;</a><br/>
<a href='https://www.instagram.com/olga.belitskaya/'>&#x1F300; &nbsp; Instagram Posts &nbsp; &nbsp;</a>
<a href='https://www.pinterest.ru/olga_belitskaya/code-style/'>&#x1F300; &nbsp; Pinterest Posts</a><br/>
In this project, we'll classify images from the dataset
<a href='https://www.kaggle.com/olgabelitskaya/art-pictogram'>Art Pictograms</a>.<br/>
The content is about 3500 images (64x64x3) with drawings
stored in the file of <i>Hierarchical Data Format (HDF5)</i>.<br/>
In the original dataset, photo files have the extension PNG and they are labeled by file prefixes.<br/>
We'll preprocess the images, represent their examples, then train neural networks.<br/> 
We are going to apply 
<a href='https://keras.io/'>Keras: a Python Deep Learning Library</a>.<br/>
    <h2>‚úíÔ∏è &nbsp; Code Modules, Helpful Functions, & Settings</h2>      
<div class='linked'><script type='text/x-sage'>
import warnings; warnings.filterwarnings('ignore')
import os,h5py,urllib,pandas as pd,numpy as np
import tensorflow as tf,pylab as pl,seaborn as sn
import tensorflow.keras.layers as tkl
import tensorflow.keras.callbacks as tkc
from tensorflow.keras.datasets import cifar10
from sklearn.metrics import classification_report
file_path='https://raw.githubusercontent.com/OlgaBelitskaya/data_kitchen/main/'
file_name='Pictograms64.h5'
model_weights='/tmp/checkpoint'
img_size=int(32)
from IPython.display import display,HTML
HTML('<style>.sagecell_input {text-shadow:4px 4px 4px #aaa;}</style>')
</script></div><br/> 
<div class='linked'><script type='text/x-sage'>
def h5file2data(h5file,cmap,img_size,resize=True):
    with h5py.File(h5file,'r') as f:
        keys=list(f.keys())
        pretty_print('file keys: '+', '.join(keys))
        images=np.array(f[keys[int(0)]])
        labels=np.array(f[keys[int(1)]])
        names=[[el.decode('utf-8') for el in f[keys[i]]]
               for i in range(int(2),len(keys))]
        f.close()
    N=images.shape[int(0)]; n=int(.1*N)
    if resize:
        images=tf.image.resize(images,[img_size,img_size]).numpy()
    shuffle_ids=np.arange(N)
    np.random.RandomState(12).shuffle(shuffle_ids)
    images=images[shuffle_ids]
    labels=np.array([labels[i][shuffle_ids] 
                     for i in range(labels.shape[int(0)])])
    x_test,x_valid,x_train=images[:n],images[n:2*n],images[2*n:]
    y_test,y_valid,y_train=labels[:,:n],labels[:,n:2*n],labels[:,2*n:]
    pretty_print('data outputs: ')
    df=pd.DataFrame([[x_train.shape,x_valid.shape,x_test.shape],
                     [x_train.dtype,x_valid.dtype,x_test.dtype],
                     [y_train.shape,y_valid.shape,y_test.shape],
                     [y_train.dtype,y_valid.dtype,y_test.dtype]],
                    columns=['train','valid','test'],
                    index=['image shape','image type',
                           'label shape','label type'])
    display(df)
    pretty_print('distribution of labels: ')
    idx=['labels %d'%(i+int(1)) for i in range(labels.shape[int(0)])]
    df=pd.DataFrame(labels,index=idx).T
    for i in range(labels.shape[int(0)]):
        df['name %d'%(i+int(1))]=[names[i][l] for l in labels[i]]
    fig=pl.figure(figsize=(10,5))    
    for i in range(labels.shape[int(0)]):
        ax=fig.add_subplot(labels.shape[int(0)],int(1),i+int(1))
        sn.countplot(x='name %s'%(i+1),data=df,palette=cmap,alpha=.5,ax=ax)
    pl.tight_layout(); pl.show()       
    return [names,x_train,x_valid,x_test,y_train,y_valid,y_test]
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
def display_images(images,labels,names,n):
    fig=pl.figure(figsize=(10,n/2))
    randch=np.random.choice(images.shape[0],size=n,replace=False)
    for i,idx in enumerate(randch):
        ax=fig.add_subplot(int(n//5)+1,5,i+1,xticks=[],yticks=[])
        ax.imshow(images[idx],cmap='bone')
        if len(labels.shape)<int(2): 
            label=[labels[idx]]
            name=[names[labels[idx]]]
        else: 
            label=[labels[:,idx]]
            name=[names[i][labels[i][idx]] for i in range(labels.shape[0])]
        ti='{} \n {}'.format(str(label),str(name))
        ax.set_title(ti,fontsize=8)
    pl.tight_layout(); pl.show()
def keras_history_plot(fit_history,fig_size=10,color='#348ABD'):
    keys=list(fit_history.history.keys())
    list_history=[fit_history.history[keys[i]] for i in range(len(keys))]
    dfkeys=pd.DataFrame(list_history).T
    dfkeys.columns=keys
    fig=pl.figure(figsize=(fig_size,fig_size//2))
    ax1=fig.add_subplot(2,1,1)
    dfkeys.iloc[:,[int(0),int(2)]].plot(
        ax=ax1,color=['slategray',color],grid=True)
    ax2=fig.add_subplot(2,1,2)
    dfkeys.iloc[:,[int(1),int(3)]].plot(
        ax=ax2,color=['slategray',color],grid=True)
    pl.tight_layout(); pl.show()
</script></div><br/>
<h2>‚úíÔ∏è &nbsp; Pictogram Data Loading</h2> 
<div class='linked'><script type='text/x-sage'>
input_file=urllib.request.urlopen(file_path+file_name)
output_file=open(file_name,'wb')
output_file.write(input_file.read())
output_file.close(); input_file.close()
[names,x_train,x_valid,x_test,y_train,y_valid,y_test]=\
h5file2data(file_name,'Pastel1',img_size)
os.remove(file_name)
xd=np.vstack([x_train,x_valid,x_test])
yd=np.hstack([y_train,y_valid,y_test])
display_images(xd,yd,names,5)
</script></div><br/>
<h2>‚úíÔ∏è &nbsp; Pictogram Selecting</h2>      
<div class='linked'><script type='text/x-sage'>
names2=['plane','car','bird','cat','deer',
        'dog','frog','horse','ship','truck']
xd=xd[np.where(yd[0]==0)]
yd=yd[1][np.where(yd[0]==0)]
cond=np.where([l in names2 for l in names[1]])[0]
cond2=np.where([l in cond for l in yd])
xd=xd[cond2]; yd=yd[cond2]
rd={1:2,4:0,6:5,7:7,8:4,9:9,10:1,11:3,12:6,13:8}
yd=np.array([rd.get(x,x) for x in yd],dtype='int8')
display_images(xd,yd,names2,5)
</script></div><br/>
    <h2>‚úíÔ∏è &nbsp; CIFAR Data Loading</h2> 
<div class='linked'><script type='text/x-sage'>
(x,y),(_,_)=cifar10.load_data()
x=np.array(x,dtype='float32')/255
y=y.reshape(-1)
n2=int(1.2*len(yd)); N=len(y); n=int(.1*N)
shuffle_ids=np.arange(N)
np.random.RandomState(23).shuffle(shuffle_ids)
shuffle_ids=shuffle_ids[:n2]
x,y=x[shuffle_ids],y[shuffle_ids]
display_images(x,y,names2,5)
</script></div><br/>
    <h2>‚úíÔ∏è &nbsp; Mixed Data</h2>
<div class='linked'><script type='text/x-sage'>
x=np.vstack([x,xd]); y=np.hstack([y,yd])
N=len(y); n=int(.1*N)
shuffle_ids=np.arange(N)
np.random.RandomState(23).shuffle(shuffle_ids)
x,y=x[shuffle_ids],y[shuffle_ids]
print([x.shape,x.dtype,y.shape,y.dtype])
gx=np.dot(x[...,:3],[.299,.587,.114])
x_test,x_valid,x_train=x[:n],x[n:2*n],x[2*n:]
gx_test,gx_valid,gx_train=gx[:n],gx[n:2*n],gx[2*n:]
y_test,y_valid,y_train=y[:n],y[n:2*n],y[2*n:]
display_images(x_train,y_train,names2,5)
display_images(gx_train,y_train,names2,5)
gx_train=gx_train.reshape(-int(1),img_size,img_size,int(1))
gx_valid=gx_valid.reshape(-int(1),img_size,img_size,int(1))
gx_test=gx_test.reshape(-int(1),img_size,img_size,int(1))
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
df=pd.DataFrame(y,columns=['label'])
df['class']=[names2[l] for l in y]
pl.figure(figsize=(10,4))
sn.countplot(x='class',data=df,palette='Pastel1',alpha=.5)
pl.title('distribution of labels',fontsize=20)
pl.tight_layout(); pl.show()
</script></div><br/>
<p>Unfortunately, we can train with guarantee only one neural network at ones.</p>
<p>Please restart the page and load the data again for training each of them.</p>
    <h2>‚úíÔ∏è &nbsp; NN Classification of Colored Images</h2>
<div class='linked'><script type='text/x-sage'>    
def model(leaky_alpha):
    model=tf.keras.Sequential()
    model.add(tkl.Conv2D(
        int(32),(int(5),int(5)),padding='same', 
        input_shape=x_train.shape[int(1):]))
    model.add(tkl.LeakyReLU(alpha=leaky_alpha))    
    model.add(tkl.MaxPooling2D(pool_size=(int(2),int(2))))
    model.add(tkl.Dropout(.2))
    model.add(tkl.Conv2D(int(96),(int(5),int(5))))
    model.add(tkl.LeakyReLU(alpha=leaky_alpha))    
    model.add(tkl.MaxPooling2D(pool_size=(int(2),int(2))))
    model.add(tkl.Dropout(.2))   
    model.add(tkl.GlobalMaxPooling2D())     
    model.add(tkl.Dense(int(512)))
    model.add(tkl.LeakyReLU(alpha=leaky_alpha))
    model.add(tkl.Dropout(.5))     
    model.add(tkl.Dense(int(10)))
    model.add(tkl.Activation('softmax'))   
    model.compile(loss='sparse_categorical_crossentropy',
                  optimizer='nadam',metrics=['accuracy'])   
    return model
model=model(float(.005))
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
checkpointer=tkc.ModelCheckpoint(
    filepath=model_weights,verbose=int(0),save_weights_only=True,
    monitor='val_accuracy',mode='max',save_best_only=True)
lr_reduction=tkc.ReduceLROnPlateau(
    monitor='val_loss',patience=int(5),verbose=int(0),factor=.8)
history=model.fit(x_train,y_train,epochs=int(10),
                  batch_size=int(16),verbose=int(2),
                  validation_data=(x_valid,y_valid),
                  callbacks=[checkpointer,lr_reduction])
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
keras_history_plot(history)
model.load_weights(model_weights)
pretty_print(model.evaluate(x_test,y_test,verbose=int(0)))
py_test=np.argmax(model.predict(x_test),axis=-1)
print(classification_report(y_test,py_test))
</script></div><br/>
    <h2>‚úíÔ∏è &nbsp; NN Classification of Grayscaled Images</h2>
<div class='linked'><script type='text/x-sage'>
def gray_model():
    model=tf.keras.Sequential()
    model.add(tkl.Conv2D(
        int(16),(int(5),int(5)),padding='same', 
        input_shape=gx_train.shape[1:]))
    model.add(tkl.LeakyReLU(alpha=.02))
    model.add(tkl.MaxPooling2D(pool_size=(int(2),int(2))))
    model.add(tkl.Dropout(.2))
    model.add(tkl.Conv2D(int(128),(int(5),int(5))))
    model.add(tkl.LeakyReLU(alpha=.02))
    model.add(tkl.MaxPooling2D(pool_size=(int(2),int(2))))
    model.add(tkl.Dropout(.2))
    model.add(tkl.GlobalMaxPooling2D())
    model.add(tkl.Dense(int(512),activation='tanh'))
    model.add(tkl.Dropout(.5))
    model.add(tkl.Dense(int(10)))
    model.add(tkl.Activation('softmax'))
    model.compile(loss='sparse_categorical_crossentropy',
                  optimizer='rmsprop',metrics=['accuracy'])
    return model
gray_model=gray_model()
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
checkpointer=tkc.ModelCheckpoint(
    filepath=model_weights,verbose=int(0),save_weights_only=True,
    monitor='val_accuracy',mode='max',save_best_only=True)
lr_reduction=tkc.ReduceLROnPlateau(
    monitor='val_loss',patience=int(5),verbose=int(0),factor=.8)
history=gray_model.fit(gx_train,y_train, epochs=int(10),
                       batch_size=int(16),verbose=int(2),
                       validation_data=(gx_valid,y_valid),
                       callbacks=[checkpointer,lr_reduction])
</script></div><br/>
<div class='linked'><script type='text/x-sage'>      
keras_history_plot(history)
gray_model.load_weights(model_weights)
pretty_print(model.evaluate(gx_test,y_test,verbose=int(0)))
pgy_test=np.argmax(gray_model.predict(x_test),axis=-1)
print(classification_report(y_test,pgy_test))
</script></div><br/>
  </body>
</html>
