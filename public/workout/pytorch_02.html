<!DOCTYPE HTML>
<html>
  <head>
    <meta charset='utf-8'>
    <meta name='viewport' content='width=device-width'>
    <title>üìë Pytorch Workout 02</title>
    <script src='https://sagecell.sagemath.org/static/embedded_sagecell.js'></script>
    <script>$(function() {
        sagecell.makeSagecell({inputLocation:'div.linked',linked:true,evalButtonText:'run'}); });
    </script>
  </head>
  <style>
  @import 'https://fonts.googleapis.com/css?family=Akronim';
  h1,h2,h3,h4 {color:darkgreen; font-family:Akronim; 
               text-shadow:4px 4px 4px #aaa; padding-left:20px;}
  p,a {color:slategray; font-size:110%; text-shadow:4px 4px 4px #aaa;}
  body {margin:5px 5px 5px 20px; background:whitesmoke; border:double slategray;}
  .sagecell .CodeMirror-scroll {min-height:3em; max-height:90em;}
  </style>
  <body>
    <div class='navbar'>
    &nbsp; &nbsp; &nbsp; &nbsp;
    <a href='https://olgabelitskaya.gitlab.io/index.html'>üåê &nbsp; Homepage &nbsp; &nbsp;</a>
    &nbsp; &nbsp; &nbsp; &nbsp;
    <a href='https://olgabelitskaya.gitlab.io/workout/index.html'>üåê &nbsp; Workout List</a>
    &nbsp; &nbsp; &nbsp; &nbsp;
    <a href='https://olgabelitskaya.github.io/README.html'>üåê &nbsp; GitHub Pages &nbsp; &nbsp;</a>
    &nbsp; &nbsp; &nbsp; &nbsp; 
    <a href='https://www.instagram.com/olga.belitskaya/'>üåê &nbsp; Instagram Posts &nbsp; &nbsp;</a> 
    &nbsp; &nbsp; &nbsp; &nbsp;    
    <a href='https://www.pinterest.ru/olga_belitskaya/code-style/'>üåê &nbsp; Pinterest Posts</a>
    </div><br/>
    <h1>üìë Pytorch Workout 02</h1>
    <h2>Code Modules</h2>
<div class='linked'><script type='text/x-sage'>
!python3 -m pip install torch==1.8.0 --user --quiet --no-warn-script-location
!python3 -m pip install torchvision==0.9.0 --user --quiet --no-warn-script-location
spath='/home/sc_work/.sage/local/lib/python3.9/site-packages'
import sys; sys.path.append(spath)
import numpy as np,pandas as pd,pylab as pl,tensorflow as tf
import zipfile,h5py,urllib,torch,torchvision
import torchvision.transforms as tvt,\
torchvision.datasets as tvd,torchvision.utils as tvu
from torchvision import models
import torch.nn.functional as tnnf,torch.nn as tnn
from torch.utils.data import Dataset as tds
from torch.utils.data import DataLoader as tdl
from IPython.core.magic import register_line_magic
dev=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
html('<style>.sagecell_input {text-shadow:4px 4px 4px #aaa;}</style>')
</script></div><br/>
    <h2>Data Loading</h2>
<div class='linked'><script type='text/x-sage'>
names=[['lowercase','uppercase'],
       [s for s in u'–∞–±–≤–≥–¥–µ—ë–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è'],
       ['single-colored paper','striped paper','squared paper','graph paper']]
path='https://raw.githubusercontent.com/OlgaBelitskaya/data/main/zip_letters/'
def file_name(lower_upper,letter,background,names=names):
    file_pre='%02d_'%names[0].index(lower_upper)
    file_pre+='%02d_'%names[1].index(letter)
    file_pre+='%02d'%names[2].index(background)
    return file_pre+'.h5'
file_names=[file_name(n0,n1,n2) for n2 in names[2] 
            for n1 in names[1] for n0 in names[0]]
file_names=[file_names[i] for i in [0,2..18]]; file_names
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
images,nlabels,labels=[],[],[]
for h5f in file_names:
    input_file=urllib.request.urlopen(path+h5f)
    output_file=open(h5f,'wb'); output_file.write(input_file.read())
    output_file.close(); input_file.close()
    with h5py.File(h5f,'r') as f:
        keys=list(f.keys()); nums=f[keys[0]].shape[0]
        print('file name: %s; '%h5f+'number of images: %d'%nums)
        images.append(np.array(f[keys[0]],dtype='float32'))
        nlabels=[el.decode('utf-8') for el in f[keys[1]]]
        labels.append(np.array(
            nums*[[names[i].index(nlabels[i]) for i in range(3)]],dtype='int32'))
        f.close(); os.remove(h5f)
images=np.concatenate(images,axis=0)
labels=np.concatenate(labels,axis=0)
images.shape,images.dtype,nlabels,labels.shape,labels.dtype
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
shuffle_ids=np.arange(images.shape[0])
np.random.RandomState(1234).shuffle(shuffle_ids)
images=images[shuffle_ids]
labels=labels[shuffle_ids]
def display_images(n_images,cols,images,labels):
    rows=n_images//cols    
    pl.figure(figsize=(cols,rows))
    for i in range(n_images):
        pl.subplot(rows,cols,i+1); pl.imshow(images[i])
        pl.title('$\\mathbb{'+str(labels[i])+'}$')
        pl.xticks([]); pl.yticks([])
    pl.tight_layout(); pl.show()
display_images(14,7,images,labels)
</script></div><br/>
    <h2>Data Processing</h2>
<div class='linked'><script type='text/x-sage'>
img_size=int(28); N=labels.shape[0]; n=int(float(.2)*N)
images=tf.image.resize(images,[img_size,img_size])
images=x=(np.dot(images.numpy(),[.299,.587,.114]))\
.reshape(-int(1),int(1),img_size,img_size)
x_test,x_train=images[:n],images[n:]
y_test,y_train=labels[:,1][:n],labels[:,1][n:]
random_seed=int(23); batch_size=int(128)
class TData(tds):
    def __init__(self,x,y):   
        self.x=torch.tensor(x,dtype=torch.float32)
        self.y=torch.tensor(y,dtype=torch.int32)
    def __getitem__(self,index):
        img,lbl=self.x[index],self.y[index]
        return img,lbl
    def __len__(self):
        return self.y.shape[int(0)]
train=TData(x_train,y_train); test=TData(x_test,y_test)
train_loader=tdl(dataset=train,shuffle=True,batch_size=batch_size)
test_loader=tdl(dataset=test,shuffle=False,batch_size=batch_size)
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
@register_line_magic
def display_examples(n):
    if n=='1': data_loader=train_loader
    if n=='2': data_loader=test_loader
    for images,labels in data_loader:  
        print('image dimensions: %s'%str(images.shape))
        print('label dimensions: %s'%str(labels.shape))
        n=np.random.randint(1,50)
        fig=pl.figure(figsize=(7,2))
        for i in range(n,n+7):
            ax=fig.add_subplot(1,7,i-n+1,xticks=[],yticks=[])
            ax.set_title('$\\mathbb{'+str(labels[i].item())+'}$')
            ax.imshow((images[i]).reshape(img_size,img_size),cmap=pl.cm.bone)
        pl.tight_layout(); pl.show(); break
%display_examples 2
</script></div><br/>
    <h2>An Example of Convolutional Conditional Variational Autoencoder</h2>
<div class='linked'><script type='text/x-sage'>
ch1,ch2,ch3=int(16),int(48),int(144)
def to_onehot(labels,num_classes,device):
    labels_ohe=torch.zeros(labels.size()[int(0)],num_classes).to(device)
    labels_ohe.scatter_(int(1),labels.view(-int(1),int(1)),int(1))
    return labels_ohe
class CondVarAE(tnn.Module):
    def __init__(self,num_features,num_latent,num_classes):
        super(CondVarAE,self).__init__()
        self.num_classes=num_classes
        # ENCODER
        self.conv_en1=tnn.Conv2d(
            in_channels=1+self.num_classes,out_channels=ch1,
            kernel_size=(int(6),int(6)),stride=(int(2),int(2)),padding=int(0))
        self.conv_en2=tnn.Conv2d(
            in_channels=ch1,out_channels=ch2,
            kernel_size=(int(4),int(4)),stride=(int(2),int(2)),padding=int(0))                        
        self.conv_en3=tnn.Conv2d(
            in_channels=ch2,out_channels=ch3,
            kernel_size=(int(2),int(2)),stride=(int(2),int(2)),padding=int(0))                     
        self.z_mean=tnn.Linear(ch3*int(2)*int(2),num_latent)
        self.z_log_var=tnn.Linear(ch3*int(2)*int(2),num_latent)
        # DECODER
        self.linear_de1=tnn.Linear(num_latent+self.num_classes,ch3*int(2)*int(2))
        self.deconv_de1=tnn.ConvTranspose2d(
            in_channels=ch3,out_channels=ch2,
            kernel_size=(int(2),int(2)),stride=(int(2),int(2)),padding=int(0))                              
        self.deconv_de2=tnn.ConvTranspose2d(
            in_channels=ch2,out_channels=ch1,
            kernel_size=(int(4),int(4)),stride=(int(3),int(3)),padding=int(1))       
        self.deconv_de3=tnn.ConvTranspose2d(
            in_channels=ch1,out_channels=1,
            kernel_size=(int(6),int(6)),stride=(int(3),int(3)),padding=int(4))        
    def reparameterize(self, z_mu, z_log_var):
        eps=torch.randn(z_mu.size(int(0)),z_mu.size(int(1))).to(dev)
        return z_mu+eps*torch.exp(z_log_var/float(2.))  
    def encoder(self,features,targets):
        onehot_targets=to_onehot(targets,self.num_classes,dev)
        onehot_targets=onehot_targets.view(-int(1),self.num_classes,int(1),int(1))        
        ones=torch.ones(features.size()[int(0)],self.num_classes,
                        features.size()[int(2)],features.size()[int(3)], 
                        dtype=features.dtype).to(dev)
        ones=ones*onehot_targets
        x=torch.cat((features,ones),dim=int(1))      
        x=self.conv_en1(x); x=tnnf.leaky_relu(x)      
        x=self.conv_en2(x); x=tnnf.leaky_relu(x)
        x=self.conv_en3(x); x=tnnf.leaky_relu(x)     
        z_mean=self.z_mean(x.view(-int(1),ch3*int(2)*int(2)))
        z_log_var=self.z_log_var(x.view(-int(1),ch3*int(2)*int(2)))
        encoded=self.reparameterize(z_mean,z_log_var)
        return z_mean,z_log_var,encoded  
    def decoder(self,encoded,targets):
        onehot_targets=to_onehot(targets,self.num_classes,dev)
        encoded=torch.cat((encoded,onehot_targets),dim=int(1))       
        x=self.linear_de1(encoded)
        x=x.view(-int(1),ch3,int(2),int(2)) 
        x=self.deconv_de1(x); x=tnnf.leaky_relu(x)      
        x=self.deconv_de2(x); x=tnnf.leaky_relu(x)
        x=self.deconv_de3(x); x=tnnf.leaky_relu(x)
        decoded=torch.sigmoid(x)
        return decoded
    def forward(self,features,targets):      
        z_mean,z_log_var,encoded=self.encoder(features,targets)
        decoded=self.decoder(encoded,targets)     
        return z_mean,z_log_var,encoded,decoded
</script></div><br/>
<div class='linked'><script type='text/x-sage'>
torch.manual_seed(random_seed)
learning_rate=float(.0015); num_latent=int(121)
num_classes=len(set(y_train))
model=CondVarAE(num_features=img_size**int(2),
                num_latent=num_latent,num_classes=num_classes)
model=model.to(dev)
optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)
</script></div><br/>
    <h2>Model Training</h2>
<div class='linked'><script type='text/x-sage'>
epochs=int(10)
for epoch in range(epochs):
    for batch_ids,(features,targets) in enumerate(train_loader):
        features=features.to(dev); targets=targets.to(dev)
        z_mean,z_log_var,encoded,decoded=model(features,targets.long())
        kl_divergence=(float(.5)*(z_mean**int(2)+torch.exp(z_log_var)-z_log_var-int(1))).sum()
        pixelwise_bce=tnnf.binary_cross_entropy(decoded,features,reduction='sum')
        cost=kl_divergence+pixelwise_bce
        optimizer.zero_grad()
        cost.backward(); optimizer.step()
        if not batch_ids%int(50):
            print ('Epoch: %03d/%03d | Batch: %03d/%03d | Cost: %.4f' 
                   %(epoch+int(1),epochs,batch_ids,len(train_loader),cost))
</script></div><br/>
    <h2>Reconstruction</h2>
<div class='linked'><script type='text/x-sage'>
num_images=int(5)
fig,axes=pl.subplots(
    nrows=2,ncols=num_images,sharex=True,sharey=True,figsize=(7,4))
original_images=features[:num_images]
decoded_images=decoded[:num_images]
for i in range(num_images):
    for ax,img in zip(axes,[original_images,decoded_images]):
        ax[i].imshow(img[i].detach().to(torch.device('cpu'))\
                     .reshape((img_size,img_size)),cmap='bone')
pl.tight_layout(); pl.show()
</script></div><br/>
    <h2>Generating</h2>
<div class='linked'><script type='text/x-sage'>
@register_line_magic
def display_gen(l):
    l=int(l); num_images=int(5)
    labels=torch.tensor([int(l)]*num_images).to(dev)
    latent_features=torch.randn(num_images,num_latent).to(dev)
    generated_images=model.decoder(latent_features,labels)
    decoded_images=generated_images[:num_images]
    fig,axes=pl.subplots(nrows=1,ncols=num_images,figsize=(7,2),sharey=True)
    for ax,img in zip(axes,decoded_images):
        ax.imshow(img.detach().to(torch.device('cpu'))\
                  .reshape((img_size,img_size)),cmap='bone')
    pl.tight_layout(); pl.show()
%display_gen 0
%display_gen 2
</script></div><br/>
  </body>
</html>
